import { SceneRenderer, CanvasMode, Size, ScenePlugin, Renderer } from '@geenee/armature';
import { PoseResult, FaceResult, HandResult, PosePoints, KeyMap, HandPoint } from '@geenee/bodyprocessors';
import { WebGLRenderer, WebGLRendererParameters } from 'three/src/renderers/WebGLRenderer';
import { Scene } from 'three/src/scenes/Scene';
import { Camera } from 'three/src/cameras/Camera';
import { Object3D } from 'three/src/core/Object3D';
import * as three from 'three';
import { Coord2D } from '@geenee/bodytracking';
import { PoseTuneParams, OutfitParams } from '@geenee/bodyrenderers-common';
import { Vector3 } from 'three/src/math/Vector3';
import { Quaternion } from 'three/src/math/Quaternion';
import { Skeleton } from 'three/src/objects/Skeleton';
import { Bone } from 'three/src/objects/Bone';
import { Material } from 'three/src/materials/Material';
import { MeshBasicMaterial } from 'three/src/materials/MeshBasicMaterial';
import { ShaderMaterial } from 'three/src/materials/ShaderMaterial';
import { MeshBVH } from 'three-mesh-bvh';
import { Texture } from 'three/src/textures/Texture';
import { CubeTexture } from 'three/src/textures/CubeTexture';
import { Color } from 'three/src/math/Color';
import { Mesh } from 'three/src/objects/Mesh';
import { SkinnedMesh } from 'three/src/objects/SkinnedMesh';
import { MeshStandardMaterial } from 'three/src/materials/MeshStandardMaterial';
import { MeshPhysicalMaterial } from 'three/src/materials/MeshPhysicalMaterial';

/**
 * Generic three.js renderer
 *
 * Extends {@link @geenee/armature!SceneRenderer} for the three.js
 * rendering engine. ThreeRenderer does basic initialization of
 * engine, scene, and camera. It's a generic class that should be
 * parameterized by type of processing results to build an app using
 * particular implementation of {@link @geenee/armature!Processor}.
 *
 * @typeParam ResultT - Type of processing results
 */
declare class ThreeRenderer<ResultT extends {} = {}> extends SceneRenderer<ResultT, Scene> {
    /** Rendering engine */
    protected renderer: WebGLRenderer;
    /** Camera instance */
    protected camera: Camera;
    /**
     * Constructor
     *
     * @param container - Container of {@link @geenee/armature!ResponsiveCanvas}
     * @param mode - Fitting mode
     * @param mirror - Mirror the output
     */
    constructor(container: HTMLElement, mode?: CanvasMode, mirror?: boolean, options?: WebGLRendererParameters);
    /**
     * Update and render the scene
     *
     * Virtual method updating and rendering 3D scene.
     * Basic implementation for three.js engine calls
     * `this.renderer.render(this.scene, this.camera)`.
     *
     * @override
     */
    protected updateScene(): void;
    /**
     * Set camera parameters
     *
     * Setups {@link ThreeRenderer#camera} instance according to
     * parameters provided by {@link @geenee/armature!Processor}.
     *
     * @param ratio - Aspect ration of input video
     * @param angle - Vertical field of view in radians
     * @override
     */
    setupCamera(ratio: number, angle: number): void;
    /**
     * Set camera parameters
     *
     * If {@link ThreeRenderer#camera} is OrthographicCamera sets
     * orthographic projection according to resolution of video.
     *
     * @param size - Resolution of input video
     * @param ratio - Aspect ration of input video
     * @override
     */
    setupVideo(size: Size, ratio?: number): void;
    /**
     * Dispose object
     *
     * Helper method to remove object from the scene and
     * recursively dispose it with all its children and
     * allocated resources like materials and textures.
     *
     * @param object - Object to dispose
     */
    protected disposeObject(object: Object3D): void;
}
/**
 * Generic plugin for {@link ThreeRenderer}
 *
 * Extends {@link @geenee/armature!ScenePlugin} for the three.js
 * rendering engine. ThreePlugin is an abstract generic class
 * simplifying library's API, it doesn't implement any logic and
 * can be used as basis for actual render plugins. It should be
 * parameterized by type of processing results to build a plugin
 * for the implementation of {@link @geenee/armature!Processor}.
 *
 * @typeParam ResultT - Type of processing results
 */
declare class ThreePlugin<ResultT extends {} = {}> extends ScenePlugin<ResultT, Scene> {
}
/**
 * Abstract renderer for {@link @geenee/bodyprocessors!PoseProcessor}
 *
 * Specializes the {@link ThreeRenderer} generic for
 * {@link @geenee/bodyprocessors!PoseResult}. This is
 * abstract renderer that doesn't implement any logic.
 */
declare class PoseRenderer extends ThreeRenderer<PoseResult> {
}
/**
 * Abstract plugin for {@link PoseRenderer}
 *
 * Specializes the {@link ThreePlugin} generic for
 * {@link @geenee/bodyprocessors!PoseResult}. This's
 * abstract plugin that doesn't implement any logic.
 */
declare class PosePlugin extends ThreePlugin<PoseResult> {
}
/**
 * Abstract renderer for {@link @geenee/bodyprocessors!FaceProcessor}
 *
 * Specializes the {@link ThreeRenderer} generic for
 * {@link @geenee/bodyprocessors!FaceResult}. This is
 * abstract renderer that doesn't implement any logic.
 */
declare class FaceRenderer extends ThreeRenderer<FaceResult> {
}
/**
 * Abstract plugin for {@link FaceRenderer}
 *
 * Specializes the {@link ThreePlugin} generic for
 * {@link @geenee/bodyprocessors!FaceResult}. This's
 * abstract plugin that doesn't implement any logic.
 */
declare class FacePlugin extends ThreePlugin<FaceResult> {
}
/**
 * Abstract renderer for {@link @geenee/bodyprocessors!HandProcessor}
 *
 * Specializes the {@link ThreeRenderer} generic for
 * {@link @geenee/bodyprocessors!HandResult}. This is
 * abstract renderer that doesn't implement any logic.
 */
declare class HandRenderer extends ThreeRenderer<HandResult> {
}
/**
 * Abstract plugin for {@link HandRenderer}
 *
 * Specializes the {@link ThreePlugin} generic for
 * {@link @geenee/bodyprocessors!HandResult}. This's
 * abstract plugin that doesn't implement any logic.
 */
declare class HandPlugin extends ThreePlugin<HandResult> {
}

/**
 * Plugin assigning head pose to a scene node
 *
 * Plugin attaches provided scene node to the head.
 * Pose of the node (translation + rotation + scale)
 * continuously updates according to pose estimation
 * by {@link @geenee/bodyprocessors!FaceProcessor}.
 * Children nodes inherently include this transform.
 * The node can be seen as a virtual placeholder for
 * real object. It's recommended to attach top-level
 * nodes that don't include transforms relative to
 * parent, otherwise head transform that is a pose
 * in the world frame will be applied on top of them
 * (will be treated as relative instead of absolute).
 * Optionally anisotropic fine-tuning of the scale can
 * be applied. In this case model will additionally
 * adapt to shape of the face. If face isn't detected
 * by FaceProcessor plugin recursively hides the node.
 * One of approaches to accurately align meshes with
 * a face/head when modeling a scene is to make them
 * children of one node at the origin and set their
 * relative transforms using face/head base mesh as
 * the reference, then instantiate HeadTrackPlugin
 * for this scene node. You can also apply relative
 * transforms of children of the head-attached parent
 * node programmatically. It's useful to add occluder
 * model (base mesh of a head) as a child of the node.
 * Another possible but less scalable approach is to
 * have all meshes be built relative to the origin and
 * aligned with the base mesh of face/head, in this
 * case you can create HeadTrackPlugin for each mesh.
 * This can be handy when parts are stored separately.
 */
declare class HeadTrackPlugin extends ThreePlugin<FaceResult> {
    protected node: three.Object3D;
    protected shapeScale: boolean;
    /**
     * Constructor
     *
     * @param node - Scene node to attach
     * @param shapeScale - Tune scale according to shape of the face
     */
    constructor(node: three.Object3D, shapeScale?: boolean);
    /**
     * Update pose of the node
     *
     * Updates node's transform (translation+rotation+scale) according to
     * the pose estimated by {@link @geenee/bodyprocessors!FaceProcessor}.
     * If face isn't detected plugin recursively hides the attached node.
     *
     * @param result - Results of video processing
     * @param stream - Captured video frame
     * @returns Promise resolving when update is finished
     * @override
     */
    update(result: FaceResult, stream: HTMLCanvasElement): Promise<void>;
}

/**
 * Plugin assigning face point pose to a scene node
 *
 * Plugin attaches provided node to the face point.
 * Pose of the node (translation + rotation + scale)
 * continuously updates according to pose estimation
 * by {@link @geenee/bodyprocessors!FaceProcessor}.
 * Children nodes inherently include this transform.
 * The node can be seen as a virtual placeholder for
 * real object. It's recommended to attach top-level
 * nodes that don't include transforms relative to
 * parent, otherwise head transform that is a pose
 * in the world frame will be applied on top of them
 * (will be treated as relative instead of absolute).
 * Optionally anisotropic fine-tuning of the scale can
 * be applied. In this case model will additionally
 * adapt to shape of the face. If face isn't detected
 * by FaceProcessor plugin recursively hides the node.
 * One of approaches to accurately align meshes with
 * a face point when modeling a scene is to make them
 * children of a node which origin coincide with the
 * corresponding vertex of the reference face mesh,
 * set their relative transforms using base mesh as
 * the reference, then instantiate FaceTrackPlugin
 * for this scene node. You can also apply relative
 * transforms of children of the face-attached parent
 * node programmatically. It's useful to add occluder
 * model (base mesh of a head) as a child of the node.
 * This can be handy when parts are stored separately.
 */
declare class FaceTrackPlugin extends ThreePlugin<FaceResult> {
    protected node: three.Object3D;
    protected facePoint: number;
    protected shapeScale: boolean;
    /**
     * Constructor
     *
     * @param node - Scene node to attach
     * @param facePoint - Index of the face vertex
     * @param shapeScale - Tune scale according to shape of the face
     */
    constructor(node: three.Object3D, facePoint?: number, shapeScale?: boolean);
    /**
     * Update pose of the model
     *
     * Updates node's pose (translation + rotation + scale) according to
     * to the estimation from {@link @geenee/bodyprocessors!FaceProcessor}.
     * If face isn't detected plugin recursively hides the attached node.
     *
     * @param result - Results of video processing
     * @param stream - Captured video frame
     * @returns Promise resolving when update is finished
     * @override
     */
    update(result: FaceResult, stream: HTMLCanvasElement): Promise<void>;
}

/**
 * Plugin assigning face mesh to geometry to a scene node
 *
 * Plugin controls geometry of a scene node. Vertices are
 * continuously updated using face mesh points estimated
 * by {@link @geenee/bodyprocessors!FaceProcessor}. Node's
 * mesh must have geometry compatible with detected face
 * mesh, preferably created from the reference face model.
 * The main requirement is that uv map must be compatible.
 * The node can be seen as a virtual placeholder for real
 * object. It's recommended to attach top-level nodes that
 * don't have transforms relative to the root, otherwise
 * this transforms will be applied to absolute positions
 * of 3d points of the face (points will act as relative).
 * One of approaches to create node for accurate face mask
 * when modeling a scene is to import reference face model
 * as top-level scene node and add one or more materials
 * which textures are compatible with reference's uv map.
 * And then instantiate FaceMaskPlugin for this scene node.
 * In {@link FaceMaskPlugin#load | load()} plugin replaces
 * geometry of attached node's mesh with one provided by
 * FaceProcessor, defined indices, uv mapping and normals.
 * As soon as uv maps of the scene mesh and the reference
 * model are compatible all materials will be applied the
 * same way as in the modeled scene. Vertices positions
 * are updated in {@link FaceMaskPlugin#update | update()}
 * method according to current face tracking estimations.
 */
declare class FaceMaskPlugin extends ThreePlugin<FaceResult> {
    protected mesh?: three.Mesh | undefined;
    /** Number of points in detected mesh */
    readonly pointCont: number;
    /**
     * Constructor
     *
     * @param mesh - Scene mesh to attach
     */
    constructor(mesh?: three.Mesh | undefined);
    /**
     * Initialize plugin
     *
     * FaceMaskPlugin replaces geometry of attached mesh
     * by compatible with face estimated by FaceProcessor.
     * As soon as uv maps of the node and the reference
     * face model are compatible, materials/textures will
     * be applied the same way as in the modeled 3d scene.
     * Defines indices, uvs, normals, while positions are
     * updated in {@link FaceMaskPlugin#update | update()}.
     *
     * @param renderer - Renderer this plugin is attached to
     * @returns Promise resolving when initialization is finished
     * @override
     */
    load(renderer: Renderer<FaceResult>): Promise<void>;
    /**
     * Update geometry of the mesh
     *
     * Updates vertex positions according to points of the face
     * estimated by {@link @geenee/bodyprocessors!FaceProcessor}.
     * If face is not detected, plugin hides the attached mesh.
     *
     * @param result - Results of video processing
     * @param stream - Captured video frame
     * @returns Promise resolving when update is finished
     * @override
     */
    update(result: FaceResult, stream: HTMLCanvasElement): Promise<void>;
    /**
     * Set/attach a scene mesh
     *
     * Rebuilds geometry of the mesh node to be compatible
     * with face mesh points estimated by FaceProcessor.
     * As soon as uv maps of the node and the reference
     * face model are compatible, materials/textures will
     * be applied the same way as in the modeled 3d scene.
     *
     * @param mesh - Scene mesh node to attach
     * @returns Promise resolving when initialization is finished
     * @virtual
     */
    setMesh(mesh?: three.Mesh): Promise<void>;
}

declare namespace PoseUtils {
    /**
     * Estimate bone position and rotation
     *
     * Position/translation of bone is defined by its head.
     * Rotation is defined by bone's basis axes: vector from
     * head to tail gives Y axis, Z axis is provided, X axis
     * is evaluated to form right-handed orthonormal basis.
     *
     * @param head - Bone's head (position)
     * @param tail - Bone's tail (end)
     * @param axisZ - Direction of Z axis
     * @returns Bone transformation
     */
    function estimateBoneYZ(head: Vector3, tail: Vector3, axisZ: Vector3): BoneTransform;
    /**
     * Estimate bone position and orientation
     *
     * Position/translation of bone is defined by its head.
     * Rotation is defined by bone's basis axes: vector from
     * head to tail gives Y axis, X axis is provided, Z axis
     * is evaluated to form right-handed orthonormal basis.
     *
     * @param head - Bone's head (position)
     * @param tail - Bone's tail (end)
     * @param axisX - Direction of X axis
     * @returns Bone transformation
     */
    function estimateBoneYX(head: Vector3, tail: Vector3, axisX: Vector3): BoneTransform;
    /**
     * Approximate rotation quaternion from basis vectors
     *
     * Y vector defined the main Y axis that says fixed.
     * Provided Z vector is preferred direction of Z axis.
     * X axis is evaluated to be perpendicular to both
     * Y and Z and form right-handed basis. Finally, Z
     * axis is re-normalized to form orthonormal basis.
     *
     * @param axisY - The main Y axis
     * @param axisZ - Preferred direction of Z axis
     * @returns Rotation quaternion
     */
    function estimateRotationYZ(axisY: Vector3, axisZ: Vector3): Quaternion;
    /**
     * Approximate rotation quaternion from basis vectors
     *
     * Y vector defined the main Y axis that says fixed.
     * Provided X vector is preferred direction of X axis.
     * Z axis is evaluated to be perpendicular to both
     * Y and X and form right-handed basis. Finally, X
     * axis is re-normalized to form orthonormal basis.
     *
     * @param axisY - The main Y axis
     * @param axisX - Preferred direction of X axis
     * @returns Rotation quaternion
     */
    function estimateRotationYX(axisY: Vector3, axisX: Vector3): Quaternion;
    /**
     * Minimal 3D rotation between two normalized vectors
     *
     * Gives the rotation that transforms vector v0 to v1.
     * which axis is the cross-product of these vectors.
     *
     * @param v0 - First unit-length vector (from)
     * @param v1 - Second unit-length vector (to)
     * @return Rotation quaternion
     */
    function rotationBetween(v0: Vector3, v1: Vector3): Quaternion;
    /**
     * Set bone transformation
     *
     * Transformation is in the world coordinate frame. If bone
     * has parent we find relative transformation to follow the
     * skeleton hierarchy. Optionally scale of parent bone can
     * be adjusted to connect head and reference (rest) position
     * of parent's tail (they have to be the same 3D point).
     *
     * @param transform - Global bone's position and rotation
     * @param bone - Reference to the bone instance
     * @param connect - Scale the parent to connect the bone
     */
    function alignBone(transform: BoneTransform, bone: Object3D, connect?: boolean): void;
    /**
     * Set bone position and connect to parent
     *
     * Position is in the world coordinate frame. If the bone
     * has a parent we find relative position to follow the
     * skeleton hierarchy. Optionally scale of parent bone can
     * be adjusted to connect head and reference (rest) position
     * of the parent's tail (they have to be the same 3D point).
     *
     * @param position - Global bone's position
     * @param bone - Reference to the bone instance
     */
    function positionBone(position: Vector3, bone: Object3D, connect?: boolean): void;
    /**
     * Set bone rotation keeping relative position
     *
     * Rotation is in the world coordinate frame. If the bone has a
     * parent we find relative rotation to follow skeleton hierarchy.
     *
     * @param rotation - Global bone's rotation
     * @param bone - Reference to the bone instance
     */
    function rotateBone(rotation: Quaternion, bone: Object3D): void;
}
/** Bone transformation */
interface BoneTransform {
    /** Head position */
    position: Vector3;
    /** Bone orientation */
    rotation: Quaternion;
}

/** List of skeleton bones */
declare const BoneList$1: readonly ["hips", "spine", "spine1", "spine2", "neck", "head", "headEnd", "shoulderL", "shoulderR", "armL", "armR", "forearmL", "forearmR", "handL", "handR", "uplegL", "uplegR", "legL", "legR", "footL", "footR", "toeL", "toeR"];
/** Union type of skeleton bones */
type BoneName$1 = typeof BoneList$1[number];
/**
 * Map of skeleton bones
 *
 * Object with properties corresponding to
 * each {@link BoneList | bone} of skeleton.
 *
 * @typeParam T - Type of mapped values
 */
type SkeletonMap$1<T> = KeyMap<BoneName$1, T>;
/** Skeleton transformations */
type SkeletonTransforms = SkeletonMap$1<BoneTransform>;
/** Skeleton - bones of the rig */
type SkeletonNodes$1 = SkeletonMap$1<three.Bone>;
/**
* Partial map of bones
*
* Object with properties corresponding to bones of skeleton.
*
* @typeParam L - List of bone names
* @typeParam T - Type of mapped values
*/
type BoneSubMap<L extends readonly BoneName$1[], T> = {
    [key in L[number]]: T;
};
/** List of spine bones */
declare const SpineBones: readonly ["hips", "spine", "spine1", "spine2", "head"];
/** Shape of spine */
type SpineCurve = BoneSubMap<typeof SpineBones, Coord2D>;
/**
 * Pose plugin aligning node's rig with keypoints
 *
 * Universal plugin aligning node's rig and pose estimated by
 * {@link @geenee/bodyprocessors!PoseProcessor}. It's a base of
 * try-on, twin, and other plugins. You can use this class as a
 * starting point and customize alignment method or add features.
 * Basically, PoseAlignPlugin evaluates positions and rotations
 * of armature bones based on 3D pose keypoints, then applies
 * these transforms to bones following the armature hierarchy.
 * Plugin supports rigs compatible with Mixamo, for example any
 * Ready Player Me avatar. This is the most common standard of
 * rigs for human-like models supported by many game engines.
 * Provided node must contain an armature among its children.
 * Armature bones must follow Mixamo / RPM naming convention.
 * Models rigged and skinned manually or using Mixamo tool can
 * variate depending on anthropomorphous topology of the model.
 * PoseAlignPlugin can apply number of fine-tuning adjustments
 * to basic alignment improving model fitting or making it look
 * more natural. {@link PoseTuneParams} explains tuning options.
 * By default the plugin is fine-tuned for RPM avatars so you
 * can simply replace person with the avatar model in the scene.
 */
declare class PoseAlignPlugin extends PosePlugin {
    protected node?: three.Object3D | undefined;
    protected tune: PoseTuneParams;
    /** Reference to model's skeleton */
    protected skeleton?: three.Skeleton;
    /** Bones of the model's rig */
    protected skeletonNodes?: SkeletonNodes$1;
    /** Shape of spine */
    protected spineCurve?: SpineCurve;
    /** Reference length of the model */
    protected avatarLength: number;
    /** Pose score threshold */
    readonly alignScore = 0.9;
    /** Keypoint visibility threshold */
    readonly alignVisibility = 0.9;
    /**
     * Constructor
     *
     * @param node - Scene node to attach
     * @param tune - Fine-tuning parameters
     */
    constructor(node?: three.Object3D | undefined, tune?: PoseTuneParams);
    /**
     * Initialize plugin
     *
     * Parses and caches the rig/armature of the attached
     * scene node (one provided to plugin's constructor).
     * Precalculates geometrical parameters of skeleton.
     *
     * @param renderer - Renderer this plugin is attached to
     * @returns Promise resolving when initialization is finished
     * @override
     */
    load(renderer: Renderer<PoseResult>): Promise<void>;
    /**
     * Reset plugin
     *
     * Removes the attached node.
     *
     * @override
     */
    unload(): void;
    /**
     * Set/attach a scene node
     *
     * Parses and caches the rig/armature of the node.
     * Precalculates geometrical parameters of skeleton.
     *
     * @param node - Scene node to attach
     * @virtual
     */
    setNode(node?: three.Object3D): void;
    /**
     * Update skeleton of the scene node
     *
     * Evaluates positions, rotations and scales of node bones
     * based on estimation of 3D keypoints, then applies these
     * transformations to bones following hierarchy of armature.
     * Optionally {@link PoseTuneParams | fine-tunes} the basic
     * alignment to improve model fitting or make it more natural.
     * You can override this method to further tune model's rig
     * using provided estimations of bones as starting point.
     * Simply call `await super.update(result, stream);` and use
     * {@link PoseAlignPlugin#skeletonNodes} member storing refs
     * to all bones of the skeleton to access transformations.
     *
     * @param result - Pose estimation results
     * @param stream - Captured video frame
     * @returns Promise resolving when update is finished
     * @override
     */
    update(result: PoseResult, stream: HTMLCanvasElement): Promise<void>;
    /**
     * Update spine skeleton
     *
     * @param anchors - Positions and axes of bones
     */
    protected updateSpine(anchors: SkeletonTransforms): void;
    /**
     * Update left hand skeleton
     *
     * @param anchors - Positions and axes of bones
     * @param points - Pose keypoints
     */
    protected updateHandL(anchors: SkeletonTransforms, points: PosePoints): void;
    /**
     * Update right hand skeleton
     *
     * @param anchors - Positions and axes of bones
     * @param points - Pose keypoints
     */
    protected updateHandR(anchors: SkeletonTransforms, points: PosePoints): void;
    /**
     * Update left leg skeleton
     *
     * @param anchors - Positions and axes of bones
     * @param points - Pose keypoints
     */
    protected updateLegL(anchors: SkeletonTransforms, points: PosePoints): void;
    /**
     * Update right leg skeleton
     *
     * @param anchors - Positions and axes of bones
     * @param points - Pose keypoints
     */
    protected updateLegR(anchors: SkeletonTransforms, points: PosePoints): void;
    /**
     * Estimate bone positions and axes
     *
     * Based on detected keypoints estimates bone transformations.
     * Position of bone if defined by 3D point itself, bone length
     * is the distance between keypoints connected by bone. Bone's
     * rotation is defined by its axes that are evaluated from
     * relative positions of adjacent keypoints. Method returns
     * only bone position and orientation axis, final transformation
     * of any bone can be found using the next bone in hierarchy.
     *
     * @param points - Pose keypoints
     * @param spineCurve - Shape of spine
     * @returns Bone transformations
     */
    protected estimateBones(points: PosePoints, spineCurve: SpineCurve): SkeletonTransforms;
    /**
     * Estimate bone position and orientation
     *
     * Position/translation of bone is defined by its head.
     * Rotation is defined by bone's basis axes, vector from
     * head to tail gives Y axis, X axis is provided, Z axis
     * is evaluated to form right-handed orthonormal basis.
     *
     * @param head - Bone's head (position)
     * @param tail - Bone's tail (end)
     * @param axisX - Direction of X axis
     * @returns Bone transformation
     */
    private estimateBone;
    /**
     * Set bone transformation
     *
     * Transformation is in the world coordinate frame. If bone
     * has parent we find relative transformation to follow the
     * skeleton hierarchy. Optionally scale of parent bone can
     * be adjusted to align head and reference (rest) position
     * of parent's tail (they have to be the same 3D point).
     *
     * @param transform - Global bone position and rotation
     * @param bone - Reference to bone instance
     * @param scale - Whether to scale parent bone
     * @virtual
     */
    protected alignBone(transform: BoneTransform, bone: three.Bone, scale?: boolean): void;
}

/**
 * Plugin implementing virtual try-on of avatar's outfit
 *
 * PoseOutfitPlugin is an extension of {@link PoseAlignPlugin}
 * that allows to specify body meshes of the avatar's node
 * as occluders and optionally hide some child meshes (parts).
 * It's a good starting point for virtual try-on applications.
 * {@link OutfitParams} defines available options of outfit.
 * You can download any Ready Player Me avatar which outfit
 * similar to final result, edit its outfit, re-skin model if
 * necessary. Then simply use this plugin to build try-on app.
 * Armature bones must follow Mixamo / RPM naming convention.
 *
 * @deprecated
 * Use {@link OccluderMaterial} or {@link OccluderMaskPlugin}
 * directly to make meshes of the node into occluders and hide
 * them manually by setEnabled(), this's more flexible approach.
 */
declare class PoseOutfitPlugin extends PoseAlignPlugin {
    protected outfit?: OutfitParams | undefined;
    /**
     * Constructor
     *
     * @param node - Scene node to attach
     * @param outfit - Occluder and hidden parts
     * @param tune - Fine-tuning parameters
     */
    constructor(node?: three.Object3D, outfit?: OutfitParams | undefined, tune?: PoseTuneParams);
    /**
     * Set/attach a scene node
     *
     * Method setNode() is extended to make occluders from specified
     * body meshes and optionally hide some child meshes according to
     * {@link OutfitParams | parameters}. Occluders are made the same
     * way {@link OccluderPlugin} does via overriding mesh materials.
     *
     * @param object - Scene node to attach
     * @returns Promise resolving when initialization is finished
     * @override
     */
    setNode(object?: three.Object3D): void;
    /**
     * Set outfit parameters
     *
     * @param node - Scene node to attach
     * @param outfit - Occluder and hidden parts
     * @returns Promise resolving when initialization is finished
     */
    setOutfit(node?: three.Object3D, outfit?: OutfitParams): void;
}

/**
 * Plugin rendering a digital twin
 *
 * {@link PoseAlignPlugin} extension for digital twins mirroring
 * the pose and residing beside a user. When rendering a twin we
 * do not translate bones to align with keypoint coordinates and
 * only preserve relative rotations. After projecting the detected
 * pose onto a twin, twin's scene node can be further transformed
 * relative to the initial position - centers of hips are the same.
 */
declare class PoseTwinPlugin extends PoseAlignPlugin {
    protected translation?: three.Vector3 | undefined;
    protected rotation?: three.Quaternion | undefined;
    protected scale?: number | undefined;
    /**
     * Constructor
     *
     * @param node - Scene node to attach
     * @param translation - Relative translation of the twin
     * @param rotation - Relative rotation of the twin
     * @param scale - Scale of the twin
     * @param tune - Fine-tuning parameters
     */
    constructor(node?: three.Object3D, translation?: three.Vector3 | undefined, rotation?: three.Quaternion | undefined, scale?: number | undefined, tune?: PoseTuneParams);
    /**
     * Update skeleton of the scene node
     *
     * Method is extended to set twin's translation,
     * rotation, and scale relative to estimated pose.
     *
     * @param result - Pose estimation results
     * @param stream - Captured video frame
     * @returns Promise resolving when update is finished
     * @override
     */
    update(result: PoseResult, stream: HTMLCanvasElement): Promise<void>;
    /**
     * Update spine skeleton
     *
     * Overridden to ignore relative scaling.
     *
     * @param anchors - Positions and axes of bones
     * @override
     */
    protected updateSpine(anchors: SkeletonTransforms): void;
    /**
     * Set bone aligning transformation
     *
     * Overridden to assign only relative rotation.
     *
     * @param transform - Global bone position and rotation
     * @param bone - Reference to bone instance
     * @override
     */
    protected alignBone(transform: BoneTransform, bone: three.Bone): void;
}

/** List of skeleton bones */
declare const BoneList: readonly ["hand", "thumb0", "thumb1", "thumb2", "thumb3", "thumbEnd", "index0", "index1", "index2", "index3", "indexEnd", "middle0", "middle1", "middle2", "middle3", "middleEnd", "ring0", "ring1", "ring2", "ring3", "ringEnd", "pinky0", "pinky1", "pinky2", "pinky3", "pinkyEnd"];
/** Union type of skeleton bones */
type BoneName = typeof BoneList[number];
/**
 * Map of skeleton bones
 *
 * Object with properties corresponding to
 * each {@link BoneList | bone} of skeleton.
 *
 * @typeParam T - Type of mapped values
 */
type SkeletonMap<T> = KeyMap<BoneName, T>;
/** Skeleton - bones of the rig */
type SkeletonNodes = SkeletonMap<Bone>;
/**
 * Hand plugin aligning node's rig with keypoints
 *
 * Universal plugin aligning node's armature and the hand pose
 * estimated by {@link @geenee/bodyprocessors!HandProcessor}.
 * Basically, HandAlignPlugin evaluates positions and rotations
 * of armature bones based on detected keypoints, then applies
 * these transforms to bones following the armature hierarchy.
 * Plugin supports rigs compatible with Clo3D and Marvelous
 * Designer avatars. This is the most common standard of rigs
 * in cloth/apparel modeling software. Controlled scene node
 * must contain an armature among its children nodes. Bones of
 * armature must follow Clo3D naming convention and hierarchy.
 */
declare class HandAlignPlugin extends HandPlugin {
    protected node?: Object3D | undefined;
    /** Reference to model's skeleton */
    protected skeleton?: Skeleton;
    /** Bones of the model's rig */
    protected skeletonNodes?: SkeletonNodes;
    /** Origin of node relative to the root bone */
    protected nodeOrigin: BoneTransform;
    /**
     * Constructor
     *
     * @param node - Scene node to attach
     */
    constructor(node?: Object3D | undefined);
    /**
     * Initialize plugin
     *
     * Parses and caches the rig/armature of the attached
     * scene node (one provided to plugin's constructor).
     * Precalculates geometrical parameters of skeleton.
     *
     * @param renderer - Renderer this plugin is attached to
     * @returns Promise resolving when initialization is finished
     * @override
     */
    load(renderer: Renderer<HandResult>): Promise<void>;
    /**
     * Reset plugin
     *
     * Clears internal state and frees all resources allocated in load().
     *
     * @override
     */
    unload(): void;
    /**
     * Set/attach a scene node
     *
     * Parses and caches the rig/armature of the node.
     * Precalculates geometrical parameters of skeleton.
     *
     * @param node - Scene node to attach
     * @virtual
     */
    setNode(node?: Object3D): void;
    /**
     * Update skeleton of the scene node
     *
     * Evaluates positions, rotations and scales of node bones
     * based on estimation of 3D keypoints, then applies these
     * transformations to bones following hierarchy of armature.
     * One can override this method to further tune model's rig
     * using provided estimations of bones as a starting point.
     * Simply call `await super.update(result, stream);` and use
     * {@link HandAlignPlugin#skeletonNodes} member storing refs
     * to all bones of the skeleton to access transformations.
     *
     * @param result - Hand estimation results
     * @param stream - Captured video frame
     * @returns Promise resolving when update is finished
     * @override
     */
    update(result: HandResult, stream: HTMLCanvasElement): Promise<void>;
    /**
     * Update finger rig (see {@link update})
     *
     * @param transforms - Finger rig ransformations
     * @param bones - Finger bones
     */
    protected updateFinger(transforms: BoneTransform[], bones: Bone[]): void;
    /**
     * Estimate bone positions and orientations
     *
     * Using detected keypoints approximates bone transformations.
     * Position of bone if defined by 3D point itself, bone length
     * is the distance between keypoints connected by bone. Bone's
     * rotation is defined by its axes that are evaluated using
     * kinematic rules and relative positions of adjacent keypoints.
     * Method returns bone position and orientation in global world
     * frame, final relative transformations are found traversing
     * skeleton hierarchy and accumulating transforms of parents.
     *
     * @param pose - Pose keypoints
     * @returns Bone transformations
     */
    protected estimateBones(pose: HandPoint[], handedness: number): {
        hand: BoneTransform;
        index: BoneTransform[];
        middle: BoneTransform[];
        ring: BoneTransform[];
        pinky: BoneTransform[];
        thumb: BoneTransform[];
    };
    /**
     * Estimate finger rig (see {@link estimateBones})
     *
     * @param points - Keypoints of the finger
     * @param origin - Hand's origin
     * @param axisY0 - Y axis in origin
     * @param axisZ0 - Z axis in origin
     * @returns Finger rig transformations
     */
    private estimateFinger;
}

/**
 * Hand plugin fitting geometry into keypoints
 *
 * Universal plugin fitting {@link HandGeometry} into a pose
 * estimated by {@link @geenee/bodyprocessors!HandProcessor}.
 * HandFitPlugin evaluates positions, rotations and scales
 * of phalanxes based on detected keypoints, and then applies
 * these transforms to sub-components of a hand geometry. Use
 * {@link HandFitPlugin#buildGeometry} to construct geometry.
 */
declare class HandFitPlugin extends HandPlugin {
    protected geometry?: HandGeometry | undefined;
    /**
     * Constructor
     *
     * @param geometry - Hand geometry to attach
     */
    constructor(geometry?: HandGeometry | undefined);
    /**
     * Set/attach a hand geometry
     *
     * @param geometry - Hand geometry to attach
     */
    setGeometry(geometry?: HandGeometry): void;
    /**
     * Build a hand geometry
     *
     * Hand geometry includes 4 fingers (index, middle, ring, pinky).
     * Each finger consists of 3 cylinders for phalanxes and 4 spheres
     * for joints beetween them and on their open ends. Phalanxes and
     * spheres have unit radiuses and lengthes for easier computations.
     *
     * @param scene - Scene to add geometry to
     * @param material - Material of the mesh
     * @returns Hand geometry
     */
    static buildGeometry(scene: Scene, material: Material): HandGeometry;
    /**
     * Update pose of the hand geometry
     *
     * Evaluates positions, rotations and scales of pahalanxes
     * based on 3D keypoints and other data, then applies these
     * transformations to components of the attached geometry.
     * One can override this method to further tune geometry of
     * a hand using default imlpementation as a starting point.
     * Simply call `await super.update(result, stream);` first
     * and adjust poses assigned to components of hand geometry.
     *
     * @param result - Hand estimation results
     * @param stream - Captured video frame
     * @returns Promise resolving when update is finished
     * @override
     */
    update(result: HandResult, stream: HTMLCanvasElement): Promise<void>;
    /**
     * Estimate phalanxes positions and orientations
     *
     * Using detected keypoints approximates transformations of phalanxes.
     * Position of a phalanx is defined by 3D point of the corresponding
     * joint. Its length is the distance between keypoints defining the
     * phalanx. Rotation is defined by its axes that are evaluated using
     * kinematic rules and relative positions of adjacent joint keypoints.
     * Method returns phalanx position & orientation in global world frame.
     *
     * @param pose - Pose keypoints
     * @returns Phalanx transformations
     */
    protected estimateBones(pose: HandPoint[], handedness: number): {
        hand: BoneTransform;
        index: BoneTransform[];
        middle: BoneTransform[];
        ring: BoneTransform[];
        pinky: BoneTransform[];
        thumb: BoneTransform[];
    };
    /**
     * Estimate finger rig (see {@link estimateBones})
     *
     * @param points - Keypoints of the finger
     * @param origin - Hand's origin
     * @param axisY0 - Y axis in origin
     * @param axisZ0 - Z axis in origin
     * @returns Finger rig transformations
     */
    private estimateFinger;
}
/** Hand geometry */
interface HandGeometry {
    /** Fingers: index, middle, ring, pinky */
    fingers: {
        /** Phalanxes: 3 cylinders */
        phalanxes: Object3D[];
        /** Joints: 4 spheres */
        joints: Object3D[];
    }[];
}

/**
 * Hand plugin fitting a ring
 *
 * Plugin fitting a ring object on a pose estimated
 * by {@link @geenee/bodyprocessors!HandProcessor}.
 * Using tracking data RingFitPlugin estimates the
 * transformation of a ring 3d object fitting it on
 * the selected finger. Plugin supports rings having
 * unit inner diameter and lying in xz plane, with
 * y axis being a center of the ring's inner circle
 * and x axis pointing in the ring's head direction.
 * Offset of a ring from world's origin along y axis
 * defines how far it will be from the phalanx start.
 * See {@link HandFitPlugin} for additional details.
 */
declare class RingFitPlugin extends HandPlugin {
    protected node?: Object3D | undefined;
    protected finger: "index" | "middle" | "ring" | "pinky";
    /**
     * Constructor
     *
     * @param node - Scene node to attach
     * @param finger - Finger to put ring on
     */
    constructor(node?: Object3D | undefined, finger?: "index" | "middle" | "ring" | "pinky");
    /**
     * Set/attach a scene node of a ring
     *
     * @param node - Scene node to attach
     */
    setNode(node?: Object3D): void;
    /**
     * Update pose of the ring's scene node
     *
     * Evaluates positions, rotations and scales of selected
     * phalanx based on 3D keypoints and tracking data, then
     * applies these transformations to the attached scene node.
     *
     * @param result - Hand estimation results
     * @param stream - Captured video frame
     * @returns Promise resolving when update is finished
     * @override
     */
    update(result: HandResult, stream: HTMLCanvasElement): Promise<void>;
    /**
     * Estimate phalanxes positions and orientations
     *
     * Using detected keypoints approximates transformations of phalanxes.
     * Position of a phalanx is defined by 3D point of the corresponding
     * joint. Its length is the distance between keypoints defining the
     * phalanx. Rotation is defined by its axes that are evaluated using
     * kinematic rules and relative positions of adjacent joint keypoints.
     * Method returns phalanx position & orientation in global world frame.
     *
     * @param pose - Pose keypoints
     * @returns Phalanx transformations
     */
    protected estimateBones(pose: HandPoint[], handedness: number): BoneTransform[];
    /**
     * Estimate finger rig (see {@link estimateBones})
     *
     * @param points - Keypoints of the finger
     * @param origin - Hand's origin
     * @param axisY0 - Y axis in origin
     * @param axisZ0 - Z axis in origin
     * @returns Finger rig transformations
     */
    private estimateFinger;
}

/**
 * Occluder plugin
 *
 * Plugin making provided node an occluder. Usually
 * node is a base mesh (average approximation) of a
 * body representing its real counterpart in a scene.
 * Occluders are not rendered by themselves but still
 * participate in occlusion queries. This is achieved
 * by setting `colorWrite=false` to all materials of
 * node's meshes. This flag tells rendering engine to
 * not write to color buffer but still write to depth
 * buffer. Then meshes are effectively not rendered
 * (fragment color write is skipped) and only occlude
 * all other meshes of the scene (during depth test).
 *
 * @deprecated Apply {@link OccluderMaterial} or use
 * {@link OccluderMaskPlugin} directly to make meshes
 * into occluders, this is more flexible approach.
 */
declare class OccluderPlugin extends ThreePlugin<any> {
    protected node: three.Object3D;
    protected renderOrder: number;
    /**
     * Constructor
     *
     * @param node - Scene node of an occluder
     * @param renderOrder - Render order (0,1,2,3)
     */
    constructor(node: three.Object3D, renderOrder?: number);
    /**
     * Initialize plugin
     *
     * Sets `colorWrite=false` to all node's materials.
     * This tells rendering engine to not write to color
     * buffer, but still write to depth buffer. This way
     * mesh is effectively not drawn (color buffer) but
     * occludes other meshes of the scene (depth test).
     *
     * @param renderer - Renderer this plugin is attached to
     * @returns Promise resolving when initialization is finished
     * @override
     */
    load(renderer: Renderer<any>): Promise<void>;
}

/**
 * Occluder material
 *
 * Occluders are elements of a scene that are not rendered
 * by themselves but still participate in occlusion queries.
 * Usually, occluder is a base mesh (average approximation)
 * of a body representing its real counterpart in a scene.
 * Occluders are used to mask visible virtual objects behind
 * them (like geometries of a 3D scene behind user's body).
 * Applying OccluderMaterial to a mesh makes it an occluder.
 * It's recommended to render occluder meshes prior to visible
 * meshes of a scene setting their renderOrder property to -1.
 */
declare class OccluderMaterial extends MeshBasicMaterial {
    /**
     * Constructor
     *
     * @param name - Name of the material in the scene
     */
    constructor(name?: string);
}

declare module "three-mesh-bvh" {
    const shaderIntersectFunction: string;
}
declare module "three/src/core/BufferGeometry" {
    interface BufferGeometry {
        bvh?: MeshBVH;
    }
}
/**
 * Refraction material
 *
 * Refraction material utilizes ray tracing approach to
 * implement refractions of light inside a mesh volume.
 * It is used for rendering of gems, diamons or glass.
 * Several parameters fine-tune ray tracing mechanics
 * and optimize for quality-performance trade offs.
 * Environment texture is used as a sperical source of
 * light refracting inside the mesh, one can use dynamic
 * texture to reflect surrounding objects of the scene.
 */
declare class RefractionMaterial extends ShaderMaterial {
    /** Constructor
     *
     * @param envMap - Environment map
     * @param color - Color of the material
     * @param opacity - Opacity of the material
     * @param bounces - Number of ray-cast bounces
     * @param ior - Refraction index
     * @param fresnel - Fresnel, strip light
     * @param aberrationStrength - RGB shift intensity
     * @param fastChroma - Use fewer ray casts for the RGB shift
     */
    constructor(envMap: Texture | CubeTexture, color?: Color, opacity?: number, bounces?: number, ior?: number, fresnel?: number, aberrationStrength?: number, fastChroma?: boolean);
}

declare function isMesh(obj: Object3D): obj is Mesh;
declare function isSkinnedMesh(obj: Object3D): obj is SkinnedMesh;
declare function isBone(obj: Object3D): obj is Bone;
declare function isCubeTexture(tex: Texture): tex is CubeTexture;
declare function isMeshStandardMaterial(mat: Material): mat is MeshStandardMaterial;
declare function isMeshPhysicalMaterial(mat: Material): mat is MeshPhysicalMaterial;

export { BoneList$1 as BoneList, type BoneName$1 as BoneName, type BoneTransform, FaceMaskPlugin, FacePlugin, FaceRenderer, FaceTrackPlugin, HandAlignPlugin, HandFitPlugin, type HandGeometry, HandPlugin, HandRenderer, HeadTrackPlugin, OccluderMaterial, OccluderPlugin, PoseAlignPlugin, PoseOutfitPlugin, PosePlugin, PoseRenderer, PoseTwinPlugin, PoseUtils, RefractionMaterial, RingFitPlugin, type SkeletonTransforms, ThreePlugin, ThreeRenderer, isBone, isCubeTexture, isMesh, isMeshPhysicalMaterial, isMeshStandardMaterial, isSkinnedMesh };
